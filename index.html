<html>

  <head>
    <meta charset="utf-8">
    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/theme/black.css">
    <link rel="stylesheet" href="lib/css/zenburn.css">
  </head>

  <body>
    <div class="reveal">
      <div class="slides">

	<section data-background="img/crs4.png" data-background-size="331px" data-background-position="center 98%">
	  <h3>Integrating Python with other languages: the Pydoop case</h3>
	  <p><small>Simone Leo &ndash; CRS4</small></p>
	</section>

	<section>
	  <h3>These slides</h3>
	  <ul>
	    <li>(browse) <a href="https://crs4.github.io/pydoop-pycon-sard" target="_blank">crs4.github.io/pydoop-pycon-sard</a></li>
	    <li>(src) <a href="https://github.com/crs4/pydoop-pycon-sard" target="_blank">github.com/crs4/pydoop-pycon-sard</a></li>
	  </ul>
	</section>

	<section id="fragments">
	  <div style="text-align:left">
	    <dl>
	      <dt>Q.</dt>
	      <dd>What is <a href="https://crs4.github.io/pydoop" target="_blank">Pydoop</a>?</dd>
	    </dl>
	  </div>
	  <div class="fragment" style="text-align:left">
	    <dl>
	      <dt>A.</dt>
	      <dd>A set of Python bindings for Hadoop</dd>
	    </dl>
	  </div>
	  <div class="fragment" style="text-align:left">
	    <dl>
	      <dt>Q.</dt>
	      <dd>OK, but what is <a href="http://hadoop.apache.org/" target="_blank">Hadoop</a>?</dd>
	    </dl>
	  </div>
	  <div class="fragment" style="text-align:left">
	    <dl>
	      <dt>A.</dt>
	      <dd>A Java distributed computing (DC) framework</dd>
	    </dl>
	  </div>
	</section>

	<section>  <!-- START HADOOP -->
	  <section>
	    <h3>Hadoop</h3>
	    <ul>
	      <li>DC framework focused on data-intensive jobs</li>
	      <li>Simple programming model (MapReduce)</li>
	      <li>Backed up by a distributed filesystem (HDFS)</li>
	      <li>Written in Java</li>
	    </ul>
	  </section>
	  <section>
	    <h3>MapReduce</h3>
	    <object type="image/svg+xml" data="img/mapreduce.svg">
	      SVG not supported
	    </object>
	  </section>
	  <section>
	    <h3>Word count &ndash; pseudocode</h3>
	    <pre><code class="hljs" data-trim>
void map(Object key, String value) {
  for (String word: tokenize(value)) {
    emit(word, 1);
  }
}

void reduce(String key, Iterator values) {
  int count = 0;
  for (int v: values) {
    count += v;
  }
  emit(key, count);
}
	    </code></pre>
	  </section>
	  <section>
	    <h3>Word count &ndash; Java</h3>
	    <pre><code class="hljs" data-trim>
public static class TokenizerMapper
    extends Mapper&lt;Object, Text, Text, IntWritable&gt; {
  private final static IntWritable one = new IntWritable(1);
  private Text word = new Text();
  public void map(Object k, Text v, Context context)
      throws IOException, InterruptedException {
    StringTokenizer itr = new StringTokenizer(v.toString());
    while (itr.hasMoreTokens()) {
      word.set(itr.nextToken());
      context.write(word, one);
    }
  }
}

public static class IntSumReducer
     extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {
  private IntWritable result = new IntWritable();
  public void reduce(Text k, Iterable&lt;IntWritable&gt; values,
      Context context)
      throws IOException, InterruptedException {
    int sum = 0;
    for (IntWritable v: values) {
      sum += v.get();
    }
    result.set(sum);
    context.write(k, result);
  }
}
	    </code></pre>
	  </section>
	</section>  <!-- END HADOOP -->

	<section>
	  <h3>Pydoop</h3>
	  <p>
	    <ul>
	      <li>Python bindings for Hadoop</li>
	      <li>MapReduce & HDFS API</li>
	      <li>Started 10 years ago with the following goal</li>
	    </ul>
	  </p>
	  <pre><code class="hljs" data-trim>
class Mapper(api.Mapper):
    def map(self, context):
        for w in context.value.split():
            context.emit(w, 1)

class Reducer(api.Reducer):
    def reduce(self, context):
        context.emit(context.key, sum(context.values))
	  </code></pre>
	</section>

	<section>  <!-- START STREAMING & CO. -->
	  <section id="fragments">
	    <h3>Already available in Hadoop</h3>
	    <p style="text-align:left"><span style="font-weight: bold">MapReduce:</span></p>
	    <div style="text-align:left">
	      <ul class="fragment">
		<li><a href="https://hadoop.apache.org/docs/r3.1.1/hadoop-streaming/HadoopStreaming.html" target="_blank">Hadoop Streaming</a></li>
		<ul>
		  <li>any language (write executable scripts)</li>
		  <li>exchange k/v pairs via stdin/stdout</li>
		</ul>
	      </ul>
	    </div>
	    <div style="text-align:left">
	      <ul class="fragment">
		<li><a href="https://hadoop.apache.org/docs/r1.2.1/api/org/apache/hadoop/mapred/pipes/package-summary.html" target="_blank">Hadoop Pipes</a> (no howto in current version!)</li>
		<ul>
		  <li>any language (a C++ client is included)</li>
		  <li>communicate with framework via socket</li>
		</ul>
	      </ul>
	    </div>
	    <p class="fragment" style="text-align:left"><span style="font-weight: bold">HDFS:</span> <a href="https://hadoop.apache.org/docs/r3.1.1/hadoop-project-dist/hadoop-hdfs/LibHdfs.html" target="_blank">libhdfs</a> (C, via JNI)</p>
	  </section>
	  <!-- Add a diagram showing the streams you get from the framework? -->
	  <section>
	    <h3>Hadoop Streaming</h3>
	    <p style="text-align:left"><small><code>mapper.py</code></small></p>
	    <pre><code class="hljs" data-trim>
for line in sys.stdin:
    for word in line.split():
        sys.stdout.write("%s\t1\n" % word)
	    </code></pre>
	    <p style="text-align:left"><small><code>reducer.py</code></small></p>
	    <pre><code class="hljs" data-trim>
out_k, out_v = None, 0
for line in sys.stdin:
    k, v = line.split("\t", 1)
    v = int(v)
    if k != out_k:
        if out_k is not None:
            sys.stdout.write("%s\t%d\n" % (out_k, out_v))
            out_v = 0
        out_k = k
    out_v += v
sys.stdout.write("%s\t%d\n" % (out_k, out_v))
	    </code></pre>
	  </section>
	  <section>
	    <h3>Hadoop Streaming &ndash; Fancy Reducer</h3>
	    <pre><code class="hljs" data-trim>
#!/usr/bin/env python

import sys
from itertools import groupby
from operator import itemgetter

def istream():
    for line in sys.stdin:
        k, v = line.split("\t", 1)
        yield k, int(v)

for k, stream in groupby(istream(), itemgetter(0)):
    v = sum(_[1] for _ in stream)
    sys.stdout.write("%s\t%d\n" % (k, v))
	    </code></pre>
	    <p><a href="https://pythonhosted.org/mrjob" target="_blank">mrjob</a> is based on Hadoop Streaming</p>
	  </section>
	  <section>
	    <h3>Hadoop Pipes</h3>
	    <p>TBD</p>
	  </section>
	</section>  <!-- END STREAMING & CO. -->

      </div>
    </div>
    <script src="lib/js/head.min.js"></script>
    <script src="js/reveal.js"></script>
    <script>
      Reveal.initialize({
        history: true,
        dependencies: [
          {src: 'plugin/highlight/highlight.js',
           async: true,
           callback: function() { hljs.initHighlightingOnLoad(); }}
        ]
      });
    </script>
  </body>

</html>
